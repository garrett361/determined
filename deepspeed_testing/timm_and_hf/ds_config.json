{"train_micro_batch_size_per_gpu": 128, "gradient_accumulation_steps": 1, "optimizer": {"type": "Adam", "params": {"lr": 1e-10}}, "zero_optimization": {"stage": 0}, "fp16": {"enabled": true}}