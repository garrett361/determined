{"train_micro_batch_size_per_gpu": 128, "gradient_accumulation_steps": 1, "optimizer": {"type": "Adam", "params": {"lr": 1e-10}}, "zero_optimization": {"stage": [0]}, "fp16": {"enabled": true, "initial_scale_power": 8}, "autotuning": {"enabled": true, "metric": "latency", "fast": true, "tuner_early_stopping": 5, "tuner_type": "random", "tuner_num_trials": 50, "start_profile_step": 3, "end_profile_step": 5}}